#B1: import tensorflow
import tensorflow as tf

#B2: turn off warning sign
import os
os.environ['TF_CPP_MIN_LOG_LEVEL']='2'

#B3: constants
T,F=1.0, -1.0
bias = 1.0

#B4: training data
train_in = [[T, T, bias], [T, F, bias], [F, T, bias], [F, F, bias]]
train_out=[[T],[F],[F],[F]]

#B5:weight matrix definition
w= tf.Variable(tf.random_normal([3,1]))

#B6:step activation function
#step(x) = {1 if x >=0; -1 otherwise}
def step(x):
    is_greater = tf.greater(x,0)
    as_float = tf.to_float(is_greater)
    doubled = tf.multiply(as_float,2)
    return tf.subtract(doubled,1)

#B7: output and error definitions
output = tf.tanh(tf.matmul(train_in,w))
error = tf.subtract(train_out, output)
mse = tf.reduce_mean(tf.square(error))
opt = tf.train.GradientDescentOptimizer(learning_rate=0.5)
train= opt.minimize(mse)

#B8: weight update definition
#delta = tf.matmul(train_in, error, transpose_a=True)
#train = tf.assign(w, tf.add(w, delta))


#B9: tensorflow session
sess = tf.Session()
sess.run(tf.global_variables_initializer())
err, target = 1,0
epoch, max_epochs = 0, 100

#B10: print W, b, and sample result
def test():
    print('\nweight/bias\n', sess.run(w))
    print('output\n', sess.run(output))
    print('mse: ', sess.run(mse), '\n')

#B11: main session
test()
while err > target and epoch <max_epochs:
    epoch += 1
    err, _ = sess.run([mse, train])
    print('epoch:', epoch, 'mse:', err)
test()
